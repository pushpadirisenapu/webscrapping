# -*- coding: utf-8 -*-
"""Copy of Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/114gYq1iFsR9QII7wvBka-XoSMJn6NtF9
"""

import pandas as pd
from bs4 import BeautifulSoup
import requests  #Making HTTP requests in Python
import re  # To perform regular expression
from tqdm import tqdm  #  A progress bar library
from datetime import datetime
from pprint import pprint

page_selector = pd.date_range(start = '1/1/2009',end = '11/1/2018',freq = 'M')
dates=[]
for i in page_selector:
  combined_date=str(i)[:4]+str(i)[5:7]
  dates.append(combined_date)
  print(len(dates[:20]))

dates[:10]

data_list = []
date_index = []

for k in tqdm(range(len(dates))):
  url = "http://www.estesparkweather.net/archive_reports.php?date="+ dates[k]
  page = requests.get(url)
  soup = BeautifulSoup(page.content, 'html.parser')
  table = soup.find_all('table')
  parsed_data = [row.text.splitlines() for row in table]
  parsed_data = parsed_data[:-9]
for l in range(len(parsed_data)):
    parsed_data[l] = parsed_data[l][2:len(parsed_data[l]):3]
for i in range(len(parsed_data)):
    raw_data = ['.'.join(re.findall("\d+",str(parsed_data[i][j].split()[:5]))) for j in range(len(parsed_data[i]))]
    print(raw_data)
    data_list.append(raw_data)
    # print(data_list)
    date_index.append(dates[k] + raw_data[0])

page = requests.get(url)

soup = BeautifulSoup(page.content, 'html.parser')
table = soup.find_all('table')

table = soup.find_all('table')

parsed_data = [row.text.splitlines() for row in table]
parsed_data = parsed_data[:-9]

pprint(parsed_data[0])

for l in range(len(parsed_data)):
    parsed_data[l] = parsed_data[l][2:len(parsed_data[l]):3]
pprint(parsed_data)

pprint(parsed_data[0])

for i in range(len(parsed_data)):
    raw_data = ['.'.join(re.findall("\d+",str(parsed_data[i][j].split()[:5]))) for j in range(len(parsed_data[i]))]
    print(raw_data)
    data_list.append(raw_data)
    # print(data_list)
    date_index.append(dates[k] + raw_data[0])

pprint(raw_data)

col = ['Average temperature (°F)', 'Average humidity (%)','Average dewpoint (°F)', 'Average barometer (in)','Average windspeed (mph)', 'Average gustspeed (mph)','Average direction (°deg)', 'Rainfall for month (in)','Rainfall for year (in)', 'Maximum rain per minute','Maximum temperature (°F)', 'Minimum temperature (°F)','Maximum humidity (%)', 'Minimum humidity (%)', 'Maximum pressure','Minimum pressure', 'Maximum windspeed (mph)',
'Maximum gust speed (mph)', 'Maximum heat index (°F)']

date_index[0]

f = [date_index[i] for i in range(len(date_index)) if len(date_index[i]) > 6]
index_col = [datetime.strptime(str(f[i]), '%Y%m%d').strftime('%Y-%m-%d') for i in range(len(f))]
pprint(index_col[:10])

formated_data = [data_list[i][1:] for i in range(len(data_list)) if len(data_list[i][1:]) == 19]

final_data = pd.DataFrame(formated_data, columns = col, index = f)
final_data.head()